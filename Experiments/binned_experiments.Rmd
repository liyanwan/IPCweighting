---
title: "binned_experiments"
author: "Liyan Wang"
date: "2024-09-29"
output: html_document
---
```{r}
rm(list = ls())
library(survival)
library(dplyr)
library(caret)
library(ggplot2)
library(knitr)
knitr::purl("~/IPCweighting/IPCW/Binned_IPCW_Function.Rmd", output = "~/IPCweighting/IPCW/Binned_IPCW_Function.R")
source("~/IPCweighting/IPCW/Binned_IPCW_Function.R")

knitr::purl("~/IPCweighting/SimulationFunction/Status_table.Rmd", output = "~/IPCweighting/SimulationFunction/Status_table.R")
source("~/IPCweighting/SimulationFunction/Status_table.R")

knitr::purl("~/IPCweighting/SimulationFunction/Data_Simulation.Rmd", output = "~/IPCweighting/SimulationFunction/Data_Simulation.R")
source("~/IPCweighting/SimulationFunction/Data_Simulation.R")
```

```{r}
# Simulate covariates and event_time
num_obs = 10000
time_point = 5
X = matrix(ncol = 0, nrow = 0)
mean_X = c()
X = get_cont_X(X, 'uniform',num_obs,1,4,"X1")
X = get_cont_X(X, 'uniform',num_obs,0.2,1,"X2")
beta = sim_beta(0.6, time_point, mean_X) #sim_beta("uniform", length(mean_X),list(start = -2, end = 2))
if (ncol(X)!=length(beta)){
  stop("X and beta are not multiplicable")
}
var_name = colnames(X)
```

```{r}
dist = "exponential"
params = list()
time_point = 5
if(dist=="exponential"){
  params$lambda_base = 0.5
}else if(dist == "Weibull"){
  params$lambda_base = 1/2
  params$alpha = 2
} else if(dist == "log-logistic"){
  params$lambda_base = 1
  params$alpha = 1/2
} else if (dist == "log-normal"){
  params$mean = 1
  params$sd = 0.7
} else{
  stop("Unsupported distribution")
}

# censor_dist = "uniform"
censor_dist = dist
censor_params = list()
if(censor_dist=="exponential"){
  censor_params$lambda_base = params$lambda_base*0.2
}else if(censor_dist == "Weibull"){
  censor_params$lambda_base = params$lambda_base*0.1
  censor_params$alpha = params$alpha/2
} else if(censor_dist == "log-logistic"){
  censor_params$lambda_base = params$lambda_base/2
  censor_params$alpha = params$alpha
} else if (censor_dist == "log-normal"){
  censor_params$mean = params$mean
  censor_params$sd = params$sd/2
} else if (censor_dist == "uniform"){
  censor_params$start = 1
  censor_params$end = 7
} else{
  stop("Unsupported distribution")
}
```

```{r}
params$lc = rowSums(sweep(X,2,beta,"*"))
power = exp(params$lc)
dt = simulation_data(num_obs, dist, params, censor_dist, censor_params, time_point, X)
dt$power = power

print(check_time_vs_status(dt,time_point))
print(check_censor_in_time_interval(dt,time_point))
result_table =data.frame(Time_Interval = character(),
                       Count = integer(),
                       stringsAsFactors = FALSE)
for (i in 1:time_point) {
  count = nrow(dt[dt$observed_time >= i - 1 & dt$observed_time <= i, ])
  result_table = rbind(result_table, 
                        data.frame(Time_Interval = paste(i-1, "to", i), 
                                   Number_of_Observations_in_Time_Tnterval = count))
}
print(result_table)
```

```{r, warning=FALSE}
# Cross Validation, binning intervals equally
max_intervals = 80
k = 5
Ghat = Get_Ghat(time_point, dt)
folds = createFolds(dt$event_time, k = k)
results = data.frame(intervals = 1:max_intervals, performance_combined = NA, performance_separate = NA)
for (num_intervals in 1:max_intervals) {
  fold_performance_separate = numeric(k)
  fold_performance_combined = numeric(k)
  for (f in 1:k) {
    train_data = dt[-folds[[f]], ]
    test_data = dt[folds[[f]], ]
    interval = seq(0, time_point, length.out = num_intervals + 1)
    model_list = bin_separate_ipcw(interval, train_data)
    pred_survival_probability = bin_surv_probability(model_list, test_data, var_name)
    test_data$pred_separate_prob = apply(pred_survival_probability, 1, prod)
    test_true_surv = (true_survival_function(dist, time_point, 
                                             params = params)) ^exp(rowSums(sweep(test_data[var_name],2,beta,"*")))
    fold_performance_separate[f] = ols_error(test_true_surv, (test_data$pred_separate_prob))

    model = bin_combined_ipcw(interval, train_data)
    test_data$pred_combine_prob = 1 - predict(model, newdata = test_data[var_name], type = "response")
    fold_performance_combined[f] = ols_error(test_true_surv,
                                             (test_data$pred_combine_prob)^num_intervals)
}
  results$performance_combined[num_intervals] = mean(fold_performance_combined)
  results$performance_separate[num_intervals] = mean(fold_performance_separate)
  
}
best_intervals_combined = results$intervals[which.min(results$performance_combined)]
best_intervals_separate = results$intervals[which.min(results$performance_separate)]

print(paste("Optimal number of intervals combined:", best_intervals_combined))
print(paste("Optimal number of intervals separate:", best_intervals_separate))
```

```{r}
# Plot of performance with respect to the number of bins
plot(x=c(1:max_intervals), y = results$performance_combined, xlab = "Number of Intervals", ylab = "OLS_Error")
plot(x=c(1:max_intervals), y = results$performance_separate, xlab = "Number of Intervals", ylab = "OLS_Error")
```

```{r}
# Compute 1 bin IPCW ols_error
true_surv = (true_survival_function(dist, time_point, params = params))^power
ipcw_est_surv = ipcw_estimate(dt,dt, time_point, var_name)
ols_ipcw = ols_error(true_surv,ipcw_est_surv)
ols_ipcw

# Compute optimal_bin IPCW ols_error
opt_interval = seq(0, time_point, length.out = best_intervals_combined + 1)
multi_ipcw_model = bin_combined_ipcw(opt_interval, dt)
multi_layer_ipcw_pred_prob = 1-(predict(multi_ipcw_model, newdata = dt[var_name], type = "response"))
ols_bin_combine_ipcw = ols_error(true_surv, (multi_layer_ipcw_pred_prob)^best_intervals_combined)
ols_bin_combine_ipcw

# Optimal_bin separate IPCW ols_error
opt_interval_separate = seq(0, time_point, length.out = best_intervals_separate + 1)
model_list = bin_separate_ipcw(opt_interval_separate, dt)
pred_survival_probability = bin_surv_probability(model_list, dt, var_name)
pred_separate_prob = apply(pred_survival_probability, 1, prod)
ols_bin_separate_ipcw = ols_error(true_surv, pred_separate_prob)
ols_bin_separate_ipcw
```

